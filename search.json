[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "cjm-pytorch-utils",
    "section": "",
    "text": "pip install cjm_pytorch_utils",
    "crumbs": [
      "cjm-pytorch-utils"
    ]
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "cjm-pytorch-utils",
    "section": "",
    "text": "pip install cjm_pytorch_utils",
    "crumbs": [
      "cjm-pytorch-utils"
    ]
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "cjm-pytorch-utils",
    "section": "How to use",
    "text": "How to use\n\nset_seed\n\nfrom cjm_pytorch_utils.core import set_seed\n\n\nseed = 1234\nset_seed(seed)\n\n\n\npil_to_tensor\n\nfrom cjm_pytorch_utils.core import pil_to_tensor\nfrom PIL import Image\nfrom torchvision import transforms\n\n\nimg_path = img_path = '../images/cat.jpg'\nsrc_img = Image.open(img_path).convert('RGB')\nprint(f\"Source Image Size: {src_img.size}\")\n\nimg_tensor = pil_to_tensor(src_img, [0.5], [0.5])\nimg_tensor.shape, img_tensor.min(), img_tensor.max()\n\nSource Image Size: (768, 512)\n\n\n(torch.Size([1, 3, 512, 768]), tensor(-1.), tensor(1.))\n\n\n\n\ntensor_to_pil\n\nfrom cjm_pytorch_utils.core import tensor_to_pil\n\n\ntensor_img = tensor_to_pil(transforms.ToTensor()(src_img))\ntensor_img\n\n\n\n\n\n\n\n\n\n\niterate_modules\n\nfrom cjm_pytorch_utils.core import iterate_modules\nimport torch\nfrom torchvision import models\n\n\nvgg = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1).features\n\nfor index, module in enumerate(iterate_modules(vgg)):\n    if type(module) == torch.nn.modules.activation.ReLU:\n        print(f\"{index}: {module}\")\n\n1: ReLU(inplace=True)\n3: ReLU(inplace=True)\n6: ReLU(inplace=True)\n8: ReLU(inplace=True)\n11: ReLU(inplace=True)\n13: ReLU(inplace=True)\n15: ReLU(inplace=True)\n18: ReLU(inplace=True)\n20: ReLU(inplace=True)\n22: ReLU(inplace=True)\n25: ReLU(inplace=True)\n27: ReLU(inplace=True)\n29: ReLU(inplace=True)\n\n\n\n\ntensor_stats_df\n\nfrom cjm_pytorch_utils.core import tensor_stats_df\n\n\ntensor_stats_df(torch.randn(1, 3, 256, 256))\n\n\n\n\n\n\n\n\n0\n\n\n\n\nmean\n0.003342\n\n\nstd\n0.99868\n\n\nmin\n-4.558271\n\n\nmax\n4.815985\n\n\nshape\n(1, 3, 256, 256)\n\n\n\n\n\n\n\n\n\nget_torch_device\n\nfrom cjm_pytorch_utils.core import get_torch_device\n\n\nget_torch_device()\n\n'cuda'\n\n\n\n\ndenorm_img_tensor\n\nfrom cjm_pytorch_utils.core import denorm_img_tensor\n\n\ntensor_to_pil(img_tensor)\n\n\n\n\n\n\n\n\n\ntensor_to_pil(denorm_img_tensor(img_tensor, [0.5], [0.5]))",
    "crumbs": [
      "cjm-pytorch-utils"
    ]
  },
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "core",
    "section": "",
    "text": "source\n\nset_seed\n\n set_seed (seed:int, deterministic:bool=False)\n\n*Sets the seed for generating random numbers in PyTorch, NumPy, and Python’s random module.\nThis function is used for reproducibility in stochastic operations, e.g. shuffling in data loaders, random initializations in neural networks, etc.\nNote: The deterministic flag does not guarantee complete reproducibility. Operations which rely on CUDA might still produce non-deterministic results.*\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nseed\nint\n\nThe seed value to be set for all random number generators.\n\n\ndeterministic\nbool\nFalse\nIf True, uses deterministic algorithms in PyTorch where possible for reproducibility, at the cost of performance.\n\n\nReturns\nNone\n\n\n\n\n\n\nseed = 1234\nset_seed(seed)\n\n\nsource\n\n\npil_to_tensor\n\n pil_to_tensor (img:&lt;module'PIL.Image'from'/opt/hostedtoolcache/Python/3.1\n                0.15/x64/lib/python3.10/site-packages/PIL/Image.py'&gt;,\n                mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n\n*Converts a PIL image to a normalized and batched PyTorch tensor.\nReturns: The normalized and batched tensor.*\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nimg\nPIL.Image\n\nThe input PIL image.\n\n\nmean\nlist\n[0.485, 0.456, 0.406]\nThe mean values for normalization.\n\n\nstd\nlist\n[0.229, 0.224, 0.225]\nThe standard deviation values for normalization.\n\n\n\nSet the path for the images directory\n\nimg_dir = Path('../images/')\nimg_dir\n\nPath('../images')\n\n\nOpen sample image\n\nimg_path = '../images/cat.jpg'\nsrc_img = Image.open(img_path).convert('RGB')\nprint(f\"Image Size: {src_img.size}\")\nsrc_img\n\nImage Size: (768, 512)\n\n\n\n\n\n\n\n\n\nConvert image to tensor\n\nimg_tensor = pil_to_tensor(src_img, [0.5], [0.5])\nimg_tensor.shape, img_tensor.min(), img_tensor.max()\n\n(torch.Size([1, 3, 512, 768]), tensor(-1.), tensor(1.))\n\n\n\nsource\n\n\ntensor_to_pil\n\n tensor_to_pil (tensor:torch.Tensor)\n\n*Convert a tensor to a PIL image.\nReturns: img (PIL.Image): The PIL image*\n\n\n\n\nType\nDetails\n\n\n\n\ntensor\nTensor\nThe tensor to be converted\n\n\n\nConvert tensor to image\n\ntensor_img = tensor_to_pil(transforms.ToTensor()(src_img))\ntensor_img\n\n\n\n\n\n\n\n\n\nsource\n\n\niterate_modules\n\n iterate_modules (module:torch.nn.modules.module.Module)\n\nA generator function that yields the children and grandchildren of a PyTorch module.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nmodule\nModule\nA PyTorch module that contains child modules to be iterated over.\n\n\n\n\nfrom torchvision import models\n\nvgg = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1).features\n\nfor index, module in enumerate(iterate_modules(vgg)):\n    if type(module) == torch.nn.modules.activation.ReLU:\n        print(f\"{index}: {module}\")\n\n1: ReLU(inplace=True)\n3: ReLU(inplace=True)\n6: ReLU(inplace=True)\n8: ReLU(inplace=True)\n11: ReLU(inplace=True)\n13: ReLU(inplace=True)\n15: ReLU(inplace=True)\n18: ReLU(inplace=True)\n20: ReLU(inplace=True)\n22: ReLU(inplace=True)\n25: ReLU(inplace=True)\n27: ReLU(inplace=True)\n29: ReLU(inplace=True)\n\n\nDownloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /home/runner/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n  0%|          | 0.00/528M [00:00&lt;?, ?B/s]  3%|2         | 13.8M/528M [00:00&lt;00:03, 143MB/s]  6%|5         | 29.6M/528M [00:00&lt;00:03, 157MB/s] 12%|#1        | 62.8M/528M [00:00&lt;00:02, 244MB/s] 19%|#8        | 97.9M/528M [00:00&lt;00:01, 293MB/s] 25%|##5       | 133M/528M [00:00&lt;00:01, 318MB/s]  32%|###1      | 167M/528M [00:00&lt;00:01, 331MB/s] 38%|###8      | 201M/528M [00:00&lt;00:01, 342MB/s] 45%|####4     | 235M/528M [00:00&lt;00:00, 345MB/s] 51%|#####     | 269M/528M [00:00&lt;00:00, 347MB/s] 57%|#####7    | 303M/528M [00:01&lt;00:00, 350MB/s] 64%|######4   | 338M/528M [00:01&lt;00:00, 355MB/s] 71%|#######   | 372M/528M [00:01&lt;00:00, 356MB/s] 77%|#######6  | 406M/528M [00:01&lt;00:00, 357MB/s] 84%|########3 | 441M/528M [00:01&lt;00:00, 359MB/s] 90%|######### | 475M/528M [00:01&lt;00:00, 358MB/s] 97%|#########6| 509M/528M [00:01&lt;00:00, 357MB/s]100%|##########| 528M/528M [00:01&lt;00:00, 334MB/s]\n\n\n\nsource\n\n\ntensor_stats_df\n\n tensor_stats_df (tensor, attrs=['mean', 'std', 'min', 'max'], shape=True)\n\nCalculate and return statistics of a given tensor as a pandas DataFrame.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntensor\n\n\nInput tensor for which statistics are to be calculated.\n\n\nattrs\nlist\n[‘mean’, ‘std’, ‘min’, ‘max’]\nList of statistics to be calculated.\n\n\nshape\nbool\nTrue\nIf True, include shape of the tensor in the output.\n\n\n\n\ntensor_stats_df(torch.randn(1, 3, 256, 256))\n\n\n\n\n\n\n\n\n0\n\n\n\n\nmean\n0.003342\n\n\nstd\n0.99868\n\n\nmin\n-4.558271\n\n\nmax\n4.815985\n\n\nshape\n(1, 3, 256, 256)\n\n\n\n\n\n\n\n\nsource\n\n\nget_torch_device\n\n get_torch_device ()\n\n*This function returns the device to be used for PyTorch computations.\nReturns: str: “mps” if Metal Performance Shaders (MPS) for MacOS is available, “cuda” if CUDA is available, “cpu” otherwise*\n\nget_torch_device()\n\n'cuda'\n\n\n\nsource\n\n\ndenorm_img_tensor\n\n denorm_img_tensor (img_tensor:torch.Tensor, mean:list, std:list)\n\n*Denormalize an image tensor.\nReturns: torch.Tensor: The tensor representing the denormalized image.*\n\n\n\n\nType\nDetails\n\n\n\n\nimg_tensor\nTensor\nThe tensor representing the normalized image.\n\n\nmean\nlist\nThe mean values used for normalization.\n\n\nstd\nlist\nThe standard deviation values used for normalization.\n\n\n\n\ntensor_to_pil(img_tensor)\n\n\n\n\n\n\n\n\n\ntensor_to_pil(denorm_img_tensor(img_tensor, [0.5], [0.5]))\n\n\n\n\n\n\n\n\n\nsource\n\n\nmove_data_to_device\n\n move_data_to_device (data, device:torch.device)\n\n*Recursively move data to the specified device.\nThis function takes a data structure (could be a tensor, list, tuple, or dictionary) and moves all tensors within the structure to the given PyTorch device.*\n\n\n\n\nType\nDetails\n\n\n\n\ndata\n\nData to move to the device.\n\n\ndevice\ndevice\nThe PyTorch device to move the data to.\n\n\n\n\ndata_tuple = (\n    {\n        'masks': torch.tensor([[[0, 1, 2], [3, 4, 5], [6, 7, 8]]], dtype=torch.int32),\n        'boxes': torch.tensor([[19.9176, 246.6063, 512.0000, 438.8571]]),\n        'labels': torch.tensor([0.]),\n    },\n    {\n        'masks': torch.tensor([[[0, 0, 0], [0, 0, 0], [0, 0, 0]]], dtype=torch.int32),\n        'boxes': torch.tensor([[19.9176, 246.6063, 512.0000, 438.8571]]),\n        'labels': torch.tensor([0.]),\n    },\n)\n\nmove_data_to_device(data_tuple, 'cpu')\n\n({'masks': tensor([[[0, 1, 2],\n           [3, 4, 5],\n           [6, 7, 8]]], dtype=torch.int32),\n  'boxes': tensor([[ 19.9176, 246.6063, 512.0000, 438.8571]]),\n  'labels': tensor([0.])},\n {'masks': tensor([[[0, 0, 0],\n           [0, 0, 0],\n           [0, 0, 0]]], dtype=torch.int32),\n  'boxes': tensor([[ 19.9176, 246.6063, 512.0000, 438.8571]]),\n  'labels': tensor([0.])})\n\n\n\nsource\n\n\nImageDataset\n\n ImageDataset (image_paths, transform=None)\n\nA PyTorch Dataset for RGB images.\n\nsource\n\n\ncompute_mean_std\n\n compute_mean_std (image_paths:List[pathlib.Path], batch_size:int=32,\n                   num_workers:int=0, image_size:int=224, transform:torchv\n                   ision.transforms.transforms.Compose=None)\n\nComputes the mean and standard deviation of images provided in image_paths.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nimage_paths\nList\n\nList of image file paths.\n\n\nbatch_size\nint\n32\nNumber of images to process in a batch.\n\n\nnum_workers\nint\n0\nNumber of subprocesses to use for data loading.\n\n\nimage_size\nint\n224\nSize to resize images to.\n\n\ntransform\nCompose\nNone\nTorchvision transforms to apply to the images.\n\n\nReturns\ndict\n\nDictionary containing ‘mean’ and ‘std’ values.\n\n\n\ncompute_mean_std(img_paths, batch_size=64)",
    "crumbs": [
      "core"
    ]
  }
]